{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../src/.env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing?\n",
    "\n",
    "## Objectives \n",
    "\n",
    "\n",
    "* Build a data pipeline that downloads price data from the internet, stores it locally, transforms it into return data, and stores the feature set.\n",
    "    - Getting the data.\n",
    "    - Schemas and index in dask.\n",
    "\n",
    "* Explore the parquet format.\n",
    "    - Reading and writing parquet files.\n",
    "    - Read datasets that are stored in distributed files.\n",
    "    - Discuss dask vs pandas as a small example of big vs small data.\n",
    "    \n",
    "* Discuss the use of environment variables for settings.\n",
    "* Discuss how to use Jupyter notebooks and source code concurrently. \n",
    "* Logging and using a standard logger.\n",
    "\n",
    "## About the Data\n",
    "\n",
    "+ We will download the prices for a list of stocks.\n",
    "+ The source is Yahoo Finance and we will use the API provided by the library yfinance.\n",
    "\n",
    "\n",
    "## Medallion Architecture\n",
    "\n",
    "+ The architecture that we are thinking about is called Medallion by [DataBricks](https://www.databricks.com/glossary/medallion-architecture). It is an ELT type of thinking, although our data is well-structured.\n",
    "\n",
    "![Medallion Architecture (DataBicks)](./img/medallion-architecture.png)\n",
    "\n",
    "+ In our case, we would like to optimize the number of times that we download data from the internet. \n",
    "+ Ultimately, we will build a pipeline manager class that will help us control the process of obtaining and transforming our data.\n",
    "\n",
    "![](./img/target_pipeline_manager.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data from Yahoo Finance\n",
    "\n",
    "Yahoo Finance provides information about public stocks in different markets. The library yfinance gives us access to a fair bit of the data in Yahoo Finance. \n",
    "\n",
    "These steps are based on the instructions in:\n",
    "\n",
    "+ [yfinance documentation](https://pypi.org/project/yfinance/)\n",
    "+ [Tutorial in geeksforgeeks.org](https://www.geeksforgeeks.org/get-financial-data-from-yahoo-finance-with-python/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ If required, install: `python -m pip install yfinance`.\n",
    "+ To download the price history of a stock, first use the following setup:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n",
    "\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice in the code chunk above:\n",
    "\n",
    "+ Libraries are ordered from high-level to low-level libraries from the package manager (pip in this case, but could be conda, poetry, etc.)\n",
    "+ The command `sys.path.append(\"../src/)` will add the `../src/` directory to the path in the Notebook's kernel. This way, we can use our modules as part of the notebook.\n",
    "+ Local modules are imported at the end. \n",
    "+ The function `get_logger()` is called with `__name__` as recommended by the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to download the historical price data for a stock, we could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"AAPL\")\n",
    "px = stock.history(start = \"2013-12-01\", end = \"2024-02-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrize the download\n",
    "\n",
    "+ Generally, we will look to separate every parameter and setting from functions.\n",
    "+ If we had a few stocks, we could cycle through them. We need a place to store the list of tickers (a db or file, for example).\n",
    "+ Store a csv file with a few stock tickers. The location of the file is a setting, the contents of this file are parameters.\n",
    "+ Use **environment variables** to pass parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ticker_file = os.getenv(\"TICKERS\")\n",
    "tickers = pd.read_csv(ticker_file).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting padas data frames\n",
    "\n",
    "+ From the [documentation](https://pandas.pydata.org/docs/user_guide/merging.html):\n",
    "\n",
    "> [`concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html#pandas.concat) makes a full copy of the data, and iteratively reusing `concat()` can create unnecessary copies. Collect all DataFrame or Series objects in a list before using `concat()`.\n",
    "\n",
    "+ We can string operation togethers using dot operations. Enclose the line in parenthesis and add linebreaks for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MMM\n",
      "Downloaded (2558, 9).\n",
      "Processing AOS\n",
      "Downloaded (2558, 9).\n",
      "Processing ABT\n",
      "Downloaded (2558, 9).\n",
      "Processing ABBV\n",
      "Downloaded (2558, 9).\n",
      "Processing ACN\n",
      "Downloaded (2558, 9).\n",
      "Processing ADBE\n",
      "Downloaded (2558, 9).\n",
      "Processing AMD\n",
      "Downloaded (2558, 9).\n",
      "Processing AES\n",
      "Downloaded (2558, 9).\n",
      "Processing AFL\n",
      "Downloaded (2558, 9).\n",
      "Processing A\n",
      "Downloaded (2558, 9).\n",
      "Processing APD\n",
      "Downloaded (2558, 9).\n",
      "Processing ABNB\n",
      "Downloaded (789, 9).\n",
      "Processing AKAM\n",
      "Downloaded (2558, 9).\n",
      "Processing ALB\n",
      "Downloaded (2558, 9).\n",
      "Processing ARE\n",
      "Downloaded (2558, 9).\n",
      "Processing ALGN\n",
      "Downloaded (2558, 9).\n",
      "Processing ALLE\n",
      "Downloaded (2558, 9).\n",
      "Processing LNT\n",
      "Downloaded (2558, 9).\n",
      "Processing ALL\n",
      "Downloaded (2558, 9).\n",
      "Processing GOOGL\n",
      "Downloaded (2558, 9).\n",
      "Final shape (49391, 9).\n"
     ]
    }
   ],
   "source": [
    "# List to hold final results\n",
    "px_list = list()\n",
    "\n",
    "for k, row in tickers.iterrows():  # Produces an iterator that returns index and row\n",
    "\n",
    "    stock = yf.Ticker(row['ticker'])\n",
    "    print(f'Processing {row[\"ticker\"]}')\n",
    "    \n",
    "    px = (stock\n",
    "          .history(start = pd.to_datetime(\"2013-12-01\"), \n",
    "                   end = pd.to_datetime(\"2024-02-01\"))\n",
    "          .reset_index()   # Reset index to get date as a column\n",
    "          .assign(ticker = row['ticker']))    # Add ticker\n",
    "    \n",
    "    if px.shape[0] == 0:\n",
    "        print(f'No data for {row[\"ticker\"]}')  # Validate: do not fail silently.\n",
    "        continue\n",
    "    print(f'Downloaded {px.shape}.')\n",
    "    px_list.append(px)\n",
    "px_dt = pd.concat(px_list, axis = 0)\n",
    "print(f'Final shape {px_dt.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability\n",
    "\n",
    "+ Keppelman (2017) defines *reliability* as:\n",
    "\n",
    "    - A system should continue to work correctly. \n",
    "    - To work correctly means performing the correct function at the desired level of performance, even in the face of adversity such as hardware or software faults, and even human error. \n",
    "\n",
    "+ *Faults* are things that can go wrong.\n",
    "+ Sytems that can cope with (certain types of) faults are called *fault-tolerant* or *resilient*.\n",
    "+ A fault is different than a failure. \n",
    "    \n",
    "    - A *fault* occurs when a component of the system deviates from spec.\n",
    "    - A *failure*  is when the system stops providing the required service to the user.\n",
    "\n",
    "+ In our simple example, we handle the fault that occurs when one ticker is not found and log it using *warning*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data in CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We have some data. How do we store it?\n",
    "+ We can compare two options, CSV and Parqruet, by measuring their performance:\n",
    "\n",
    "    - Time to save.\n",
    "    - Space required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_size(path='.'):\n",
    "    '''Returns the total size of files contained in path.'''\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.getenv(\"TEMP_DATA\")\n",
    "os.makedirs(temp, exist_ok=True)\n",
    "stock_path = os.path.join(temp, \"stock_px.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to dt ((49391, 9))csv took 0.7578959465026855 seconds.\n",
      "Csv file size 5.904789 MB\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "px_dt.to_csv(stock_path, index = False)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Writing to dt ({px_dt.shape})csv took {end - start} seconds.')\n",
    "print(f'Csv file size { os.path.getsize(stock_path)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data to Parquet\n",
    "\n",
    "### Dask \n",
    "\n",
    "We can work with with large data sets and parquet files. In fact, recent versions of pandas support pyarrow data types and future versions will require a pyarrow backend. The pyarrow library is an interface between Python and the Appache Arrow project. The [parquet data format](https://parquet.apache.org/) and [Arrow](https://arrow.apache.org/docs/python/parquet.html) are projects of the Apache Foundation.\n",
    "\n",
    "However, Dask is much more than an interface to Arrow: Dask provides parallel and distributed computing on pandas-like dataframes. It is also relatively easy to use, bridging a gap between pandas and Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "dask.config.set({'dataframe.query-planning': True})\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dd ((49391, 9)) to parquet took 0.15486812591552734 seconds.\n",
      "Parquet file size 2.241246 MB\n"
     ]
    }
   ],
   "source": [
    "px_dd = dd.from_pandas(px_dt, npartitions = len(tickers))\n",
    "parquet_path = os.path.join(temp, \"stock_px.parquet\")\n",
    "\n",
    "start = time.time()\n",
    "px_dd.to_parquet(parquet_path, engine = \"pyarrow\")\n",
    "end = time.time()\n",
    "\n",
    "print(f'Writing dd ({px_dt.shape}) to parquet took {end - start} seconds.')\n",
    "print(f'Parquet file size { get_dir_size(parquet_path)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet files and Dask Dataframes\n",
    "\n",
    "+ Parquet files are immutable: once written, they cannot be modified.\n",
    "+ Dask DataFrames are a useful implementation to manipulate data stored in parquets.\n",
    "+ Parquet and Dask are not the same: parquet is a file format that can be accessed by many applications and programming languages (Python, R, PowerBI, etc.), while Dask is a package in Python to work with large datasets using distributed computation.\n",
    "+ **Dask is not for everything** (see [Dask DataFrames Best Practices](https://docs.dask.org/en/stable/dataframe-best-practices.html)). \n",
    "\n",
    "    - Consider cases suchas small to larrge joins, where the small dataframe fits in memory, but the large one does not. \n",
    "    - If possible, use pandas: reduce, then use pandas.\n",
    "    - Pandas performance tips apply to Dask.\n",
    "    - Use the index: it is beneficial to have a well-defined index in Dask DataFrames, as it may speed up searching (filtering) the data. A one-dimensional index is allowed.\n",
    "    - Avoid (or minimize) full-data shuffling: indexing is an expensive operations. \n",
    "    - Some joins are more expensive than others. \n",
    "\n",
    "        * Not expensive:\n",
    "\n",
    "            - Join a Dask DataFrame with a pandas DataFrame.\n",
    "            - Join a Dask DataFrame with another Dask DataFrame of a single partition.\n",
    "            - Join Dask DataFrames along their indexes.\n",
    "\n",
    "        * Expensive:\n",
    "\n",
    "            - Join Dask DataFrames along columns that are not their index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we store prices?\n",
    "\n",
    "+ We can store our data as a single blob. This can be difficult to maintain, especially because parquet files are immutable.\n",
    "+ Strategy: organize data files by ticker and date. Update only latest month.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")\n",
    "\n",
    "for ticker in px_dt.ticker.unique():\n",
    "    ticker_dt = px_dt[px_dt.ticker == ticker]\n",
    "    ticker_dt = ticker_dt.assign(year = ticker_dt.Date.dt.year)\n",
    "    for yr in ticker_dt.year.unique():\n",
    "        yr_dt = ticker_dt[ticker_dt.year == yr]\n",
    "        yr_path = os.path.join(PRICE_DATA, ticker, f\"{ticker}_{yr}.parquet\")\n",
    "        os.makedirs(os.path.dirname(yr_path), exist_ok=True)\n",
    "        yr_dt.to_parquet(yr_path, engine = \"pyarrow\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would we want to store data this way?\n",
    "\n",
    "+ Easier to maintain. We do not update old data, only recent data.\n",
    "+ We can also access all files as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Transform and Save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "+ Parquet files can be read individually or as a collection.\n",
    "+ `dd.read_parquet()` can take a list (collection) of files as input.\n",
    "+ Use `glob` to get the collection of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "parquet_files = glob(os.path.join(PRICE_DATA, \"*/*.parquet\"))\n",
    "dd_px = dd.read_parquet(parquet_files).set_index(\"ticker\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "+ This transformation step will create a *Features* data set. In our case, features will be stock returns (we obtained prices).\n",
    "+ Dask dataframes work like pandas dataframes: in particular, we can perform groupby and apply operations.\n",
    "+ Notice the use of [an anonymous (lambda) function](https://realpython.com/python-lambda/) in the apply statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdsim\\AppData\\Local\\Temp\\ipykernel_6696\\3091835559.py:2: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  dd_rets = (dd_px.groupby('ticker', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dd_rets = (dd_px.groupby('ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(Close_lag_1 = x['Close'].shift(1))\n",
    ").assign(\n",
    "    returns = lambda x: x['Close']/x['Close_lag_1'] - 1\n",
    ").assign(\n",
    "    positive_return = lambda x: (x['returns'] > 0)*1\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Exection\n",
    "\n",
    "What does `dd_rets` contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask_expr.expr.DataFrame: expr=Assign(frame=Assign(frame=Assign(frame=Assign(frame=Assign(frame=Assign(frame=GroupByApply(frame=SetIndex(frame=ReadParquet(6e7e226), _other=ticker, options={}), observed=False, group_keys=False, func=<function <lambda> at 0x00000225BA5276A0>, meta=_NoDefault.no_default, args=(), kwargs={})))))))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_rets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Dask is a lazy execution framework: commands will not execute until they are required. \n",
    "+ To trigger an execution in dask use `.compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>year</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>returns</th>\n",
       "      <th>positive_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2013-12-02 00:00:00-05:00</td>\n",
       "      <td>35.052676</td>\n",
       "      <td>35.183785</td>\n",
       "      <td>34.816674</td>\n",
       "      <td>34.882229</td>\n",
       "      <td>2039962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2013-12-03 00:00:00-05:00</td>\n",
       "      <td>34.692122</td>\n",
       "      <td>34.856014</td>\n",
       "      <td>34.456121</td>\n",
       "      <td>34.698677</td>\n",
       "      <td>3462706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>34.882229</td>\n",
       "      <td>-0.005262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2013-12-04 00:00:00-05:00</td>\n",
       "      <td>34.639681</td>\n",
       "      <td>35.288686</td>\n",
       "      <td>34.561017</td>\n",
       "      <td>35.124794</td>\n",
       "      <td>3377288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>34.698677</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2013-12-05 00:00:00-05:00</td>\n",
       "      <td>34.974005</td>\n",
       "      <td>35.269005</td>\n",
       "      <td>34.823227</td>\n",
       "      <td>35.072338</td>\n",
       "      <td>2530939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>35.124794</td>\n",
       "      <td>-0.001493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2013-12-06 00:00:00-05:00</td>\n",
       "      <td>35.242803</td>\n",
       "      <td>36.009803</td>\n",
       "      <td>35.242803</td>\n",
       "      <td>35.944248</td>\n",
       "      <td>4268513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>35.072338</td>\n",
       "      <td>0.024860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>2024-01-25 00:00:00-05:00</td>\n",
       "      <td>92.247775</td>\n",
       "      <td>94.706929</td>\n",
       "      <td>92.080554</td>\n",
       "      <td>94.411835</td>\n",
       "      <td>6122900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>91.716599</td>\n",
       "      <td>0.029387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>2024-01-26 00:00:00-05:00</td>\n",
       "      <td>94.647914</td>\n",
       "      <td>95.316805</td>\n",
       "      <td>94.224940</td>\n",
       "      <td>94.421669</td>\n",
       "      <td>3720200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>94.411835</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>2024-01-29 00:00:00-05:00</td>\n",
       "      <td>94.431509</td>\n",
       "      <td>95.306967</td>\n",
       "      <td>93.880661</td>\n",
       "      <td>94.805298</td>\n",
       "      <td>3800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>94.421669</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>2024-01-30 00:00:00-05:00</td>\n",
       "      <td>94.598729</td>\n",
       "      <td>94.933178</td>\n",
       "      <td>93.231440</td>\n",
       "      <td>94.185593</td>\n",
       "      <td>3200500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>94.805298</td>\n",
       "      <td>-0.006537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>2024-01-31 00:00:00-05:00</td>\n",
       "      <td>94.372490</td>\n",
       "      <td>94.372490</td>\n",
       "      <td>92.621573</td>\n",
       "      <td>92.808464</td>\n",
       "      <td>6906800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>94.185593</td>\n",
       "      <td>-0.014621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49391 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date       Open       High        Low      Close  \\\n",
       "ticker                                                                         \n",
       "A      2013-12-02 00:00:00-05:00  35.052676  35.183785  34.816674  34.882229   \n",
       "A      2013-12-03 00:00:00-05:00  34.692122  34.856014  34.456121  34.698677   \n",
       "A      2013-12-04 00:00:00-05:00  34.639681  35.288686  34.561017  35.124794   \n",
       "A      2013-12-05 00:00:00-05:00  34.974005  35.269005  34.823227  35.072338   \n",
       "A      2013-12-06 00:00:00-05:00  35.242803  36.009803  35.242803  35.944248   \n",
       "...                          ...        ...        ...        ...        ...   \n",
       "MMM    2024-01-25 00:00:00-05:00  92.247775  94.706929  92.080554  94.411835   \n",
       "MMM    2024-01-26 00:00:00-05:00  94.647914  95.316805  94.224940  94.421669   \n",
       "MMM    2024-01-29 00:00:00-05:00  94.431509  95.306967  93.880661  94.805298   \n",
       "MMM    2024-01-30 00:00:00-05:00  94.598729  94.933178  93.231440  94.185593   \n",
       "MMM    2024-01-31 00:00:00-05:00  94.372490  94.372490  92.621573  92.808464   \n",
       "\n",
       "         Volume  Dividends  Stock Splits  year  Close_lag_1   returns  \\\n",
       "ticker                                                                  \n",
       "A       2039962        0.0           0.0  2013          NaN       NaN   \n",
       "A       3462706        0.0           0.0  2013    34.882229 -0.005262   \n",
       "A       3377288        0.0           0.0  2013    34.698677  0.012280   \n",
       "A       2530939        0.0           0.0  2013    35.124794 -0.001493   \n",
       "A       4268513        0.0           0.0  2013    35.072338  0.024860   \n",
       "...         ...        ...           ...   ...          ...       ...   \n",
       "MMM     6122900        0.0           0.0  2024    91.716599  0.029387   \n",
       "MMM     3720200        0.0           0.0  2024    94.411835  0.000104   \n",
       "MMM     3800000        0.0           0.0  2024    94.421669  0.004063   \n",
       "MMM     3200500        0.0           0.0  2024    94.805298 -0.006537   \n",
       "MMM     6906800        0.0           0.0  2024    94.185593 -0.014621   \n",
       "\n",
       "        positive_return  \n",
       "ticker                   \n",
       "A                     0  \n",
       "A                     0  \n",
       "A                     1  \n",
       "A                     0  \n",
       "A                     1  \n",
       "...                 ...  \n",
       "MMM                   1  \n",
       "MMM                   1  \n",
       "MMM                   1  \n",
       "MMM                   0  \n",
       "MMM                   0  \n",
       "\n",
       "[49391 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_rets.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "\n",
    "+ Apply transformations to calculate daily returns\n",
    "+ Store the enriched data, the silver dataset, in a new directory.\n",
    "+ Should we keep the same namespace? All columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = os.getenv(\"FEATURES_DATA\")\n",
    "dd_rets.to_parquet(features_path, engine = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few notes\n",
    "\n",
    "# Jupyter? \n",
    "\n",
    "+ We have drafted our code in a Jupyter Notebook. \n",
    "+ Finalized code should be written in Python modules.\n",
    "\n",
    "## Object oriented programming?\n",
    "\n",
    "+ We can use classes to keep parameters and functions together.\n",
    "+ We *could* use Object Oriented Programming, but parallelization of data manipulation and modelling tasks benefits from *Functional Programming*.\n",
    "+ An Idea: \n",
    "\n",
    "    - [Data Oriented Programming](https://blog.klipse.tech/dop/2022/06/22/principles-of-dop.html).\n",
    "    - Use the class to bundle together parameters and functions.\n",
    "    - Use stateless operations and treat all data objects as immutable (we do not modify them, we overwrite them).\n",
    "    - Take advantage of [`@staticmethod`](https://realpython.com/instance-class-and-static-methods-demystified/).\n",
    "\n",
    "The code is in `./src/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original design was:\n",
    "\n",
    "![](./img/target_pipeline_manager.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we demonstrate how our class implementation works.\n",
    "\n",
    "Before we begin, clean the price directory (we will download everything again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean up before start\n",
    "\n",
    "import shutil\n",
    "if os.path.exists(PRICE_DATA):\n",
    "    shutil.rmtree(PRICE_DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate a DataManager object and download all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manager import DataManager\n",
    "dm = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 19:03:03,195, data_manager.py, 43, INFO, Getting price data for all tickers.\n",
      "2024-03-06 19:03:03,195, data_manager.py, 43, INFO, Getting price data for all tickers.\n",
      "2024-03-06 19:03:03,198, data_manager.py, 52, INFO, Getting tickers from ../data/tickers/sp500_wiki.csv\n",
      "2024-03-06 19:03:03,198, data_manager.py, 52, INFO, Getting tickers from ../data/tickers/sp500_wiki.csv\n",
      "2024-03-06 19:03:03,204, data_manager.py, 58, INFO, Processing all tickers\n",
      "2024-03-06 19:03:03,204, data_manager.py, 58, INFO, Processing all tickers\n",
      "2024-03-06 19:03:03,208, data_manager.py, 73, INFO, Processing ticker MMM\n",
      "2024-03-06 19:03:03,208, data_manager.py, 73, INFO, Processing ticker MMM\n",
      "2024-03-06 19:03:03,210, data_manager.py, 108, INFO, Getting stock price data for MMM from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:03,210, data_manager.py, 108, INFO, Getting stock price data for MMM from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:03,814, data_manager.py, 82, INFO, Saving data for MMM by year\n",
      "2024-03-06 19:03:03,814, data_manager.py, 82, INFO, Saving data for MMM by year\n",
      "2024-03-06 19:03:04,403, data_manager.py, 73, INFO, Processing ticker AOS\n",
      "2024-03-06 19:03:04,403, data_manager.py, 73, INFO, Processing ticker AOS\n",
      "2024-03-06 19:03:04,405, data_manager.py, 108, INFO, Getting stock price data for AOS from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:04,405, data_manager.py, 108, INFO, Getting stock price data for AOS from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:04,968, data_manager.py, 82, INFO, Saving data for AOS by year\n",
      "2024-03-06 19:03:04,968, data_manager.py, 82, INFO, Saving data for AOS by year\n",
      "2024-03-06 19:03:05,532, data_manager.py, 73, INFO, Processing ticker ABT\n",
      "2024-03-06 19:03:05,532, data_manager.py, 73, INFO, Processing ticker ABT\n",
      "2024-03-06 19:03:05,534, data_manager.py, 108, INFO, Getting stock price data for ABT from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:05,534, data_manager.py, 108, INFO, Getting stock price data for ABT from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:05,832, data_manager.py, 82, INFO, Saving data for ABT by year\n",
      "2024-03-06 19:03:05,832, data_manager.py, 82, INFO, Saving data for ABT by year\n",
      "2024-03-06 19:03:06,410, data_manager.py, 73, INFO, Processing ticker ABBV\n",
      "2024-03-06 19:03:06,410, data_manager.py, 73, INFO, Processing ticker ABBV\n",
      "2024-03-06 19:03:06,411, data_manager.py, 108, INFO, Getting stock price data for ABBV from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:06,411, data_manager.py, 108, INFO, Getting stock price data for ABBV from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:06,559, data_manager.py, 82, INFO, Saving data for ABBV by year\n",
      "2024-03-06 19:03:06,559, data_manager.py, 82, INFO, Saving data for ABBV by year\n",
      "2024-03-06 19:03:06,859, data_manager.py, 73, INFO, Processing ticker ACN\n",
      "2024-03-06 19:03:06,859, data_manager.py, 73, INFO, Processing ticker ACN\n",
      "2024-03-06 19:03:06,861, data_manager.py, 108, INFO, Getting stock price data for ACN from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:06,861, data_manager.py, 108, INFO, Getting stock price data for ACN from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:07,057, data_manager.py, 82, INFO, Saving data for ACN by year\n",
      "2024-03-06 19:03:07,057, data_manager.py, 82, INFO, Saving data for ACN by year\n",
      "2024-03-06 19:03:07,631, data_manager.py, 73, INFO, Processing ticker ADBE\n",
      "2024-03-06 19:03:07,631, data_manager.py, 73, INFO, Processing ticker ADBE\n",
      "2024-03-06 19:03:07,633, data_manager.py, 108, INFO, Getting stock price data for ADBE from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:07,633, data_manager.py, 108, INFO, Getting stock price data for ADBE from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:07,922, data_manager.py, 82, INFO, Saving data for ADBE by year\n",
      "2024-03-06 19:03:07,922, data_manager.py, 82, INFO, Saving data for ADBE by year\n",
      "2024-03-06 19:03:08,521, data_manager.py, 73, INFO, Processing ticker AMD\n",
      "2024-03-06 19:03:08,521, data_manager.py, 73, INFO, Processing ticker AMD\n",
      "2024-03-06 19:03:08,522, data_manager.py, 108, INFO, Getting stock price data for AMD from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:08,522, data_manager.py, 108, INFO, Getting stock price data for AMD from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:08,988, data_manager.py, 82, INFO, Saving data for AMD by year\n",
      "2024-03-06 19:03:08,988, data_manager.py, 82, INFO, Saving data for AMD by year\n",
      "2024-03-06 19:03:09,568, data_manager.py, 73, INFO, Processing ticker AES\n",
      "2024-03-06 19:03:09,568, data_manager.py, 73, INFO, Processing ticker AES\n",
      "2024-03-06 19:03:09,569, data_manager.py, 108, INFO, Getting stock price data for AES from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:09,569, data_manager.py, 108, INFO, Getting stock price data for AES from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:09,813, data_manager.py, 82, INFO, Saving data for AES by year\n",
      "2024-03-06 19:03:09,813, data_manager.py, 82, INFO, Saving data for AES by year\n",
      "2024-03-06 19:03:10,392, data_manager.py, 73, INFO, Processing ticker AFL\n",
      "2024-03-06 19:03:10,392, data_manager.py, 73, INFO, Processing ticker AFL\n",
      "2024-03-06 19:03:10,393, data_manager.py, 108, INFO, Getting stock price data for AFL from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:10,393, data_manager.py, 108, INFO, Getting stock price data for AFL from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:10,780, data_manager.py, 82, INFO, Saving data for AFL by year\n",
      "2024-03-06 19:03:10,780, data_manager.py, 82, INFO, Saving data for AFL by year\n",
      "2024-03-06 19:03:11,350, data_manager.py, 73, INFO, Processing ticker A\n",
      "2024-03-06 19:03:11,350, data_manager.py, 73, INFO, Processing ticker A\n",
      "2024-03-06 19:03:11,352, data_manager.py, 108, INFO, Getting stock price data for A from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:11,352, data_manager.py, 108, INFO, Getting stock price data for A from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:11,786, data_manager.py, 82, INFO, Saving data for A by year\n",
      "2024-03-06 19:03:11,786, data_manager.py, 82, INFO, Saving data for A by year\n",
      "2024-03-06 19:03:12,363, data_manager.py, 73, INFO, Processing ticker APD\n",
      "2024-03-06 19:03:12,363, data_manager.py, 73, INFO, Processing ticker APD\n",
      "2024-03-06 19:03:12,364, data_manager.py, 108, INFO, Getting stock price data for APD from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:12,364, data_manager.py, 108, INFO, Getting stock price data for APD from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:12,706, data_manager.py, 82, INFO, Saving data for APD by year\n",
      "2024-03-06 19:03:12,706, data_manager.py, 82, INFO, Saving data for APD by year\n",
      "2024-03-06 19:03:13,271, data_manager.py, 73, INFO, Processing ticker ABNB\n",
      "2024-03-06 19:03:13,271, data_manager.py, 73, INFO, Processing ticker ABNB\n",
      "2024-03-06 19:03:13,273, data_manager.py, 108, INFO, Getting stock price data for ABNB from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:13,273, data_manager.py, 108, INFO, Getting stock price data for ABNB from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:13,365, data_manager.py, 82, INFO, Saving data for ABNB by year\n",
      "2024-03-06 19:03:13,365, data_manager.py, 82, INFO, Saving data for ABNB by year\n",
      "2024-03-06 19:03:13,494, data_manager.py, 73, INFO, Processing ticker AKAM\n",
      "2024-03-06 19:03:13,494, data_manager.py, 73, INFO, Processing ticker AKAM\n",
      "2024-03-06 19:03:13,495, data_manager.py, 108, INFO, Getting stock price data for AKAM from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:13,495, data_manager.py, 108, INFO, Getting stock price data for AKAM from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:13,695, data_manager.py, 82, INFO, Saving data for AKAM by year\n",
      "2024-03-06 19:03:13,695, data_manager.py, 82, INFO, Saving data for AKAM by year\n",
      "2024-03-06 19:03:14,268, data_manager.py, 73, INFO, Processing ticker ALB\n",
      "2024-03-06 19:03:14,268, data_manager.py, 73, INFO, Processing ticker ALB\n",
      "2024-03-06 19:03:14,269, data_manager.py, 108, INFO, Getting stock price data for ALB from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:14,269, data_manager.py, 108, INFO, Getting stock price data for ALB from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:14,679, data_manager.py, 82, INFO, Saving data for ALB by year\n",
      "2024-03-06 19:03:14,679, data_manager.py, 82, INFO, Saving data for ALB by year\n",
      "2024-03-06 19:03:15,297, data_manager.py, 73, INFO, Processing ticker ARE\n",
      "2024-03-06 19:03:15,297, data_manager.py, 73, INFO, Processing ticker ARE\n",
      "2024-03-06 19:03:15,298, data_manager.py, 108, INFO, Getting stock price data for ARE from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:15,298, data_manager.py, 108, INFO, Getting stock price data for ARE from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:15,575, data_manager.py, 82, INFO, Saving data for ARE by year\n",
      "2024-03-06 19:03:15,575, data_manager.py, 82, INFO, Saving data for ARE by year\n",
      "2024-03-06 19:03:16,139, data_manager.py, 73, INFO, Processing ticker ALGN\n",
      "2024-03-06 19:03:16,139, data_manager.py, 73, INFO, Processing ticker ALGN\n",
      "2024-03-06 19:03:16,140, data_manager.py, 108, INFO, Getting stock price data for ALGN from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:16,140, data_manager.py, 108, INFO, Getting stock price data for ALGN from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:16,638, data_manager.py, 82, INFO, Saving data for ALGN by year\n",
      "2024-03-06 19:03:16,638, data_manager.py, 82, INFO, Saving data for ALGN by year\n",
      "2024-03-06 19:03:17,235, data_manager.py, 73, INFO, Processing ticker ALLE\n",
      "2024-03-06 19:03:17,235, data_manager.py, 73, INFO, Processing ticker ALLE\n",
      "2024-03-06 19:03:17,236, data_manager.py, 108, INFO, Getting stock price data for ALLE from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:17,236, data_manager.py, 108, INFO, Getting stock price data for ALLE from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:17,383, data_manager.py, 82, INFO, Saving data for ALLE by year\n",
      "2024-03-06 19:03:17,383, data_manager.py, 82, INFO, Saving data for ALLE by year\n",
      "2024-03-06 19:03:17,652, data_manager.py, 73, INFO, Processing ticker LNT\n",
      "2024-03-06 19:03:17,652, data_manager.py, 73, INFO, Processing ticker LNT\n",
      "2024-03-06 19:03:17,653, data_manager.py, 108, INFO, Getting stock price data for LNT from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:17,653, data_manager.py, 108, INFO, Getting stock price data for LNT from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:17,896, data_manager.py, 82, INFO, Saving data for LNT by year\n",
      "2024-03-06 19:03:17,896, data_manager.py, 82, INFO, Saving data for LNT by year\n",
      "2024-03-06 19:03:18,481, data_manager.py, 73, INFO, Processing ticker ALL\n",
      "2024-03-06 19:03:18,481, data_manager.py, 73, INFO, Processing ticker ALL\n",
      "2024-03-06 19:03:18,482, data_manager.py, 108, INFO, Getting stock price data for ALL from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:18,482, data_manager.py, 108, INFO, Getting stock price data for ALL from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:18,768, data_manager.py, 82, INFO, Saving data for ALL by year\n",
      "2024-03-06 19:03:18,768, data_manager.py, 82, INFO, Saving data for ALL by year\n",
      "2024-03-06 19:03:19,386, data_manager.py, 73, INFO, Processing ticker GOOGL\n",
      "2024-03-06 19:03:19,386, data_manager.py, 73, INFO, Processing ticker GOOGL\n",
      "2024-03-06 19:03:19,387, data_manager.py, 108, INFO, Getting stock price data for GOOGL from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:19,387, data_manager.py, 108, INFO, Getting stock price data for GOOGL from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:19,620, data_manager.py, 82, INFO, Saving data for GOOGL by year\n",
      "2024-03-06 19:03:19,620, data_manager.py, 82, INFO, Saving data for GOOGL by year\n",
      "2024-03-06 19:03:20,101, data_manager.py, 73, INFO, Processing ticker GOOG\n",
      "2024-03-06 19:03:20,101, data_manager.py, 73, INFO, Processing ticker GOOG\n",
      "2024-03-06 19:03:20,103, data_manager.py, 108, INFO, Getting stock price data for GOOG from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:20,103, data_manager.py, 108, INFO, Getting stock price data for GOOG from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:20,354, data_manager.py, 82, INFO, Saving data for GOOG by year\n",
      "2024-03-06 19:03:20,354, data_manager.py, 82, INFO, Saving data for GOOG by year\n",
      "2024-03-06 19:03:20,843, data_manager.py, 73, INFO, Processing ticker MO\n",
      "2024-03-06 19:03:20,843, data_manager.py, 73, INFO, Processing ticker MO\n",
      "2024-03-06 19:03:20,844, data_manager.py, 108, INFO, Getting stock price data for MO from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:20,844, data_manager.py, 108, INFO, Getting stock price data for MO from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:21,334, data_manager.py, 82, INFO, Saving data for MO by year\n",
      "2024-03-06 19:03:21,334, data_manager.py, 82, INFO, Saving data for MO by year\n",
      "2024-03-06 19:03:21,903, data_manager.py, 73, INFO, Processing ticker AMZN\n",
      "2024-03-06 19:03:21,903, data_manager.py, 73, INFO, Processing ticker AMZN\n",
      "2024-03-06 19:03:21,904, data_manager.py, 108, INFO, Getting stock price data for AMZN from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:21,904, data_manager.py, 108, INFO, Getting stock price data for AMZN from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:22,391, data_manager.py, 82, INFO, Saving data for AMZN by year\n",
      "2024-03-06 19:03:22,391, data_manager.py, 82, INFO, Saving data for AMZN by year\n",
      "2024-03-06 19:03:22,953, data_manager.py, 73, INFO, Processing ticker AMCR\n",
      "2024-03-06 19:03:22,953, data_manager.py, 73, INFO, Processing ticker AMCR\n",
      "2024-03-06 19:03:22,954, data_manager.py, 108, INFO, Getting stock price data for AMCR from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:22,954, data_manager.py, 108, INFO, Getting stock price data for AMCR from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:23,161, data_manager.py, 82, INFO, Saving data for AMCR by year\n",
      "2024-03-06 19:03:23,161, data_manager.py, 82, INFO, Saving data for AMCR by year\n",
      "2024-03-06 19:03:23,461, data_manager.py, 73, INFO, Processing ticker AEE\n",
      "2024-03-06 19:03:23,461, data_manager.py, 73, INFO, Processing ticker AEE\n",
      "2024-03-06 19:03:23,462, data_manager.py, 108, INFO, Getting stock price data for AEE from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:23,462, data_manager.py, 108, INFO, Getting stock price data for AEE from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:23,838, data_manager.py, 82, INFO, Saving data for AEE by year\n",
      "2024-03-06 19:03:23,838, data_manager.py, 82, INFO, Saving data for AEE by year\n",
      "2024-03-06 19:03:24,426, data_manager.py, 73, INFO, Processing ticker AAL\n",
      "2024-03-06 19:03:24,426, data_manager.py, 73, INFO, Processing ticker AAL\n",
      "2024-03-06 19:03:24,427, data_manager.py, 108, INFO, Getting stock price data for AAL from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:24,427, data_manager.py, 108, INFO, Getting stock price data for AAL from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:24,606, data_manager.py, 82, INFO, Saving data for AAL by year\n",
      "2024-03-06 19:03:24,606, data_manager.py, 82, INFO, Saving data for AAL by year\n",
      "2024-03-06 19:03:25,090, data_manager.py, 73, INFO, Processing ticker AEP\n",
      "2024-03-06 19:03:25,090, data_manager.py, 73, INFO, Processing ticker AEP\n",
      "2024-03-06 19:03:25,091, data_manager.py, 108, INFO, Getting stock price data for AEP from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:25,091, data_manager.py, 108, INFO, Getting stock price data for AEP from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:25,526, data_manager.py, 82, INFO, Saving data for AEP by year\n",
      "2024-03-06 19:03:25,526, data_manager.py, 82, INFO, Saving data for AEP by year\n",
      "2024-03-06 19:03:26,090, data_manager.py, 73, INFO, Processing ticker AXP\n",
      "2024-03-06 19:03:26,090, data_manager.py, 73, INFO, Processing ticker AXP\n",
      "2024-03-06 19:03:26,091, data_manager.py, 108, INFO, Getting stock price data for AXP from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:26,091, data_manager.py, 108, INFO, Getting stock price data for AXP from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:26,581, data_manager.py, 82, INFO, Saving data for AXP by year\n",
      "2024-03-06 19:03:26,581, data_manager.py, 82, INFO, Saving data for AXP by year\n",
      "2024-03-06 19:03:27,182, data_manager.py, 73, INFO, Processing ticker AIG\n",
      "2024-03-06 19:03:27,182, data_manager.py, 73, INFO, Processing ticker AIG\n",
      "2024-03-06 19:03:27,184, data_manager.py, 108, INFO, Getting stock price data for AIG from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:27,184, data_manager.py, 108, INFO, Getting stock price data for AIG from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:27,474, data_manager.py, 82, INFO, Saving data for AIG by year\n",
      "2024-03-06 19:03:27,474, data_manager.py, 82, INFO, Saving data for AIG by year\n",
      "2024-03-06 19:03:28,077, data_manager.py, 73, INFO, Processing ticker AMT\n",
      "2024-03-06 19:03:28,077, data_manager.py, 73, INFO, Processing ticker AMT\n",
      "2024-03-06 19:03:28,078, data_manager.py, 108, INFO, Getting stock price data for AMT from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:28,078, data_manager.py, 108, INFO, Getting stock price data for AMT from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:28,281, data_manager.py, 82, INFO, Saving data for AMT by year\n",
      "2024-03-06 19:03:28,281, data_manager.py, 82, INFO, Saving data for AMT by year\n",
      "2024-03-06 19:03:28,867, data_manager.py, 73, INFO, Processing ticker AWK\n",
      "2024-03-06 19:03:28,867, data_manager.py, 73, INFO, Processing ticker AWK\n",
      "2024-03-06 19:03:28,869, data_manager.py, 108, INFO, Getting stock price data for AWK from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:28,869, data_manager.py, 108, INFO, Getting stock price data for AWK from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:29,131, data_manager.py, 82, INFO, Saving data for AWK by year\n",
      "2024-03-06 19:03:29,131, data_manager.py, 82, INFO, Saving data for AWK by year\n",
      "2024-03-06 19:03:29,528, data_manager.py, 73, INFO, Processing ticker AMP\n",
      "2024-03-06 19:03:29,528, data_manager.py, 73, INFO, Processing ticker AMP\n",
      "2024-03-06 19:03:29,530, data_manager.py, 108, INFO, Getting stock price data for AMP from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:29,530, data_manager.py, 108, INFO, Getting stock price data for AMP from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:29,732, data_manager.py, 82, INFO, Saving data for AMP by year\n",
      "2024-03-06 19:03:29,732, data_manager.py, 82, INFO, Saving data for AMP by year\n",
      "2024-03-06 19:03:30,194, data_manager.py, 73, INFO, Processing ticker AME\n",
      "2024-03-06 19:03:30,194, data_manager.py, 73, INFO, Processing ticker AME\n",
      "2024-03-06 19:03:30,195, data_manager.py, 108, INFO, Getting stock price data for AME from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:30,195, data_manager.py, 108, INFO, Getting stock price data for AME from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:30,549, data_manager.py, 82, INFO, Saving data for AME by year\n",
      "2024-03-06 19:03:30,549, data_manager.py, 82, INFO, Saving data for AME by year\n",
      "2024-03-06 19:03:31,145, data_manager.py, 73, INFO, Processing ticker AMGN\n",
      "2024-03-06 19:03:31,145, data_manager.py, 73, INFO, Processing ticker AMGN\n",
      "2024-03-06 19:03:31,147, data_manager.py, 108, INFO, Getting stock price data for AMGN from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:31,147, data_manager.py, 108, INFO, Getting stock price data for AMGN from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:31,664, data_manager.py, 82, INFO, Saving data for AMGN by year\n",
      "2024-03-06 19:03:31,664, data_manager.py, 82, INFO, Saving data for AMGN by year\n",
      "2024-03-06 19:03:32,288, data_manager.py, 73, INFO, Processing ticker APH\n",
      "2024-03-06 19:03:32,288, data_manager.py, 73, INFO, Processing ticker APH\n",
      "2024-03-06 19:03:32,290, data_manager.py, 108, INFO, Getting stock price data for APH from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:32,290, data_manager.py, 108, INFO, Getting stock price data for APH from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:32,539, data_manager.py, 82, INFO, Saving data for APH by year\n",
      "2024-03-06 19:03:32,539, data_manager.py, 82, INFO, Saving data for APH by year\n",
      "2024-03-06 19:03:33,125, data_manager.py, 73, INFO, Processing ticker ADI\n",
      "2024-03-06 19:03:33,125, data_manager.py, 73, INFO, Processing ticker ADI\n",
      "2024-03-06 19:03:33,126, data_manager.py, 108, INFO, Getting stock price data for ADI from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:33,126, data_manager.py, 108, INFO, Getting stock price data for ADI from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:33,393, data_manager.py, 82, INFO, Saving data for ADI by year\n",
      "2024-03-06 19:03:33,393, data_manager.py, 82, INFO, Saving data for ADI by year\n",
      "2024-03-06 19:03:33,983, data_manager.py, 73, INFO, Processing ticker ANSS\n",
      "2024-03-06 19:03:33,983, data_manager.py, 73, INFO, Processing ticker ANSS\n",
      "2024-03-06 19:03:33,984, data_manager.py, 108, INFO, Getting stock price data for ANSS from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:33,984, data_manager.py, 108, INFO, Getting stock price data for ANSS from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:34,352, data_manager.py, 82, INFO, Saving data for ANSS by year\n",
      "2024-03-06 19:03:34,352, data_manager.py, 82, INFO, Saving data for ANSS by year\n",
      "2024-03-06 19:03:34,971, data_manager.py, 73, INFO, Processing ticker AON\n",
      "2024-03-06 19:03:34,971, data_manager.py, 73, INFO, Processing ticker AON\n",
      "2024-03-06 19:03:34,973, data_manager.py, 108, INFO, Getting stock price data for AON from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:34,973, data_manager.py, 108, INFO, Getting stock price data for AON from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:35,512, data_manager.py, 82, INFO, Saving data for AON by year\n",
      "2024-03-06 19:03:35,512, data_manager.py, 82, INFO, Saving data for AON by year\n",
      "2024-03-06 19:03:36,083, data_manager.py, 73, INFO, Processing ticker APA\n",
      "2024-03-06 19:03:36,083, data_manager.py, 73, INFO, Processing ticker APA\n",
      "2024-03-06 19:03:36,084, data_manager.py, 108, INFO, Getting stock price data for APA from 2000-01-01 to 2024-03-06\n",
      "2024-03-06 19:03:36,084, data_manager.py, 108, INFO, Getting stock price data for APA from 2000-01-01 to 2024-03-06\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "2024-03-06 19:03:36,444, data_manager.py, 82, INFO, Saving data for APA by year\n",
      "2024-03-06 19:03:36,444, data_manager.py, 82, INFO, Saving data for APA by year\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dm.download_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add features to our data set and save to a *feature store*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 19:03:48,189, data_manager.py, 117, INFO, Creating features data.\n",
      "2024-03-06 19:03:48,189, data_manager.py, 117, INFO, Creating features data.\n",
      "2024-03-06 19:03:48,191, data_manager.py, 128, INFO, Loading price data from ../data/prices/\n",
      "2024-03-06 19:03:48,191, data_manager.py, 128, INFO, Loading price data from ../data/prices/\n",
      "2024-03-06 19:03:48,403, data_manager.py, 136, INFO, Creating features\n",
      "2024-03-06 19:03:48,403, data_manager.py, 136, INFO, Creating features\n",
      "c:\\Users\\tdsim\\OneDrive\\Desktop\\DSI\\Slides\\production\\notebooks\\../src\\data_manager.py:140: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  .apply(\n",
      "2024-03-06 19:03:48,414, data_manager.py, 154, INFO, Creating target\n",
      "2024-03-06 19:03:48,414, data_manager.py, 154, INFO, Creating target\n",
      "c:\\Users\\tdsim\\OneDrive\\Desktop\\DSI\\Slides\\production\\notebooks\\../src\\data_manager.py:155: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  self.features = (self.features.groupby('ticker', group_keys=False).apply(\n",
      "2024-03-06 19:03:48,423, data_manager.py, 164, INFO, Saving features to ../data/features/stock_features.parquet\n",
      "2024-03-06 19:03:48,423, data_manager.py, 164, INFO, Saving features to ../data/features/stock_features.parquet\n"
     ]
    }
   ],
   "source": [
    "dm.featurize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
